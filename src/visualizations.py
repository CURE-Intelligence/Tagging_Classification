# Import the wordcloud library
import gensim.models
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import itertools
from collections import Counter
import numpy as np
from bertopic import BERTopic
import matplotlib
from umap import UMAP
import pandas as pd
from typing import List, Tuple
import pyLDAvis.gensim
import gensim.corpora as corpora
from src.topic_modelling.lda_base_model import print_topics
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix


#LDA Visualizations
def generate_word_cloud_from_bigrams(bigrams_data: List[List[str]]):

    """
    Generate a word cloud from a list of lists of bigrams.

    Args:
        bigrams_data (List[List[str]]): List of lists where each sublist contains bigrams.

    Returns:
        matplotlib.image.AxesImage: Word cloud image.
    """

    # Flatten the list of lists into a single string of bigrams separated by spaces
    #flattened_bigrams = ' '.join([' '.join(bigrams) for bigrams in bigrams_data])

    # Suppose final_text_processed is your list of words after preprocessing
    words_flat = [word for sublist in bigrams_data for word in sublist]
    word_counts = Counter(words_flat)

    # Set 'milch' count to 1 (or any desired number)
    word_counts['milch'] = 1

    # Generate the word cloud using adjusted frequencies
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_counts)

    # Display the word cloud
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.show()


    # Generate word cloud
    #wordcloud = WordCloud(background_color="white", max_words=1000, contour_width=10, contour_color='steelblue')
    #wordcloud.generate(flattened_bigrams)

    # Plot the word cloud
    #plt.figure(figsize=(10, 6))
    #plt.imshow(wordcloud, interpolation="bilinear")
    #plt.axis("off")
    #plt.tight_layout()
    #plt.show()

def visualize_lda_topics(lda_topics, num_topics=5, num_words=15, start_from_index=1):
    """
    Visualizes the topics generated by an LDA model using separate horizontal bar charts for each topic,
    starting from the second most frequent word.

    Args:
        lda_topics (list of tuples): List of topics as returned by LDA model's show_topics method.
        num_words (int): Number of top words per topic to display. Default is 10.
        start_from_index (int): Index to start displaying words from. Default is 1 (second word).
    """

    for topic_num, topic in lda_topics:
        # Splitting the topic string and extracting word weights
        words_weights = topic.split(' + ')
        words = [ww.split('*')[1].strip().strip('"') for ww in words_weights[start_from_index:num_words]]
        weights = [float(ww.split('*')[0]) for ww in words_weights[start_from_index:num_words]]

        # Plotting the horizontal bar chart for the topic
        plt.figure(figsize=(10, 5))
        plt.barh(words, weights, color='blue')  # Use barh for horizontal bars
        plt.xlabel('Weights')
        plt.ylabel('Words')
        plt.title(f'Top Words in LDA Topic {topic_num + 1} (starting from second most frequent)')
        plt.xticks(rotation=45)
        plt.gca().invert_yaxis()  # Invert y-axis to have the highest weight on top
        plt.show()


    # Extracting topic labels and top words

# Example usage:
# Assuming lda_model is already trained using Gensim
# lda_model = ...  # Your trained LDA model
# visualize_lda_topics(lda_model)

def show_words_corresponding_to_keywords(model: gensim.models.LdaMulticore, keywords: List[str]):

    topics = model.show_topics()
    # Initialize a dictionary to store the topic names
    topic_names = {}

    # Iterate through each topic
    for topic_id, topic in topics:
        # Extract the top keywords for the current topic
        words = [word_weight.split('*')[1].strip('"') for word_weight in topic.split(' + ')]
        # Match the top keywords to your predefined keywords
        matched_keywords = [keyword for keyword in keywords if keyword in words]
        # Generate a name for the topic based on matched keywords
        topic_name = ', '.join(matched_keywords) if matched_keywords else "Miscellaneous"
        # Store the topic name in the dictionary
        topic_names[topic_id] = matched_keywords

    # Plotting the bar chart
    fig, ax = plt.subplots(figsize=(10, 6))

    # Preparing data for plotting
    topics_ids = list(topic_names.keys())
    all_words = [word for words in topic_names.values() for word in words]
    unique_words = list(set(all_words))

    # Create a bar plot for each topic
    for topic_id in topics_ids:
        words = topic_names[topic_id]
        for word in words:
            word_index = unique_words.index(word)
            ax.bar(topic_id + word_index*0.1, 1, width=0.1, label=word if topic_id == 0 else "")

    # Customizing the plot
    ax.set_xticks(topics_ids)
    ax.set_xticklabels([f"Topic {tid}" for tid in topics_ids])
    ax.set_xlabel('Topics')
    ax.set_ylabel('Word Occurrence')
    ax.set_title('Top Words in LDA Topics')
    ax.legend(loc='upper right')

    plt.show()

def show_keyword_distributions(model: gensim.models.LdaMulticore, keywords: List[str]):

    # Initialize a dictionary to hold word frequencies for each topic
    topic_word_frequencies = {}

    topics_words = model.show_topics()

    # Iterate over the topics
    for topic_id, topic_words in topics_words:
        word_frequencies = Counter(word for word, _ in model.show_topic(topic_id))
        topic_word_frequencies[f"Topic {topic_id}"] = {word: word_frequencies[word] for word in keywords}

    # Print the word frequencies for each topic
    for topic, frequencies in topic_word_frequencies.items():
        print(topic)
        for word, frequency in frequencies.items():
            print(f"  {word}: {frequency}")

    # Plotting the word frequencies for each topic
    fig, ax = plt.subplots(figsize=(12, 8))

    # Data preparation
    topics = list(topic_word_frequencies.keys())
    word_labels = keywords
    data = np.array([[frequencies[word] for word in word_labels] for frequencies in topic_word_frequencies.values()])

    # Create the bar chart
    x = np.arange(len(word_labels))  # the label locations
    width = 0.15  # the width of the bars

    for i, topic in enumerate(topics):
        ax.bar(x + i * width, data[i], width, label=topic)

    # Add some text for labels, title and custom x-axis tick labels, etc.
    ax.set_xlabel('Words')
    ax.set_ylabel('Frequencies')
    ax.set_title('Word frequencies by topic')
    ax.set_xticks(x + width / len(topics))
    ax.set_xticklabels(word_labels)
    ax.legend()

    fig.tight_layout()

    plt.show()


#BERT Topic Visualizations

# Get the frequency of each topic
def visualize_frequencies(topic_model: BERTopic):

    topic_freq = topic_model.get_topic_info().iloc[0:6, :]

    # Plot the topic frequencies
    plt.figure(figsize=(30, 20))
    plt.bar(topic_freq['Name'], topic_freq['Count'])
    plt.xlabel('Topic')
    plt.ylabel('Number of Documents')
    plt.title('Topic Frequencies')
    plt.show()

def visualize_topic_word_clouds(topic_model: BERTopic):

    topic_words = topic_model.get_topic_info().iloc[0:6, :]

    # Create a word cloud
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(topic_words))

    # Plot the word cloud
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title('Word Cloud for Topic 0')
    plt.show()

def visualize_scatter_topics(topic_model: BERTopic, sentences: List[str], topics: List[int]) :
    #Perform dimensionality reduction with UMAP
    topic_embeddings = topic_model._extract_embeddings(sentences, method="document")
    umap_model = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit(topic_embeddings)
    df = pd.DataFrame(umap_model.embedding_, columns=["x", "y"])

    df["topic"] = topics
    top_n = len(df['topic'].unique())  # Number of topics to visualize
    fontsize = 12

    # Filter data for the top 2 topics
    to_plot = df[df['topic'].isin(range(top_n))]

    # Define a colormap for the 2 topics
    cmap = matplotlib.colors.ListedColormap(['#FF5722', '#03A9F4', "#00AA99"])  # Red and Blue

    #define the topic names dynamically ()
    # ---To Be done----
    df_topics = topic_model.get_topic_info()
    # Define the range for keys
    key_range = range(len(df))
    # Construct the dictionary dynamically
    topic_info = {key: value for key, value in zip(key_range, df_topics['Name'])}

    # Visualize outliers + inliers
    fig, ax = plt.subplots(figsize=(15, 15))

    # Scatter plot for outliers (if any)
    outliers = df[~df['topic'].isin(range(top_n))]
    scatter_outliers = ax.scatter(outliers['x'], outliers['y'], c="#E0E0E0", s=1, alpha=.3)

    # Scatter plot for non-outliers (topics)
    scatter = ax.scatter(to_plot['x'], to_plot['y'], c=to_plot['topic'], cmap=cmap, s=50, alpha=0.7)

    # Add topic names to clusters (centroid of each topic)
    centroids = to_plot.groupby("topic").mean()
    for topic_id, centroid in centroids.iterrows():
        topic_info = f"Topic {topic_id}: {topic_info[topic_id]}"
        ax.text(centroid['x'], centroid['y'] * 1.01, topic_info, fontsize=fontsize, horizontalalignment='center')

    # Set plot title and labels
    ax.set_title(f"BERTopic - Top {top_n} Topics", fontsize=fontsize)
    ax.set_xlabel("UMAP Dimension 1", fontsize=fontsize)
    ax.set_ylabel("UMAP Dimension 2", fontsize=fontsize)
    ax.grid(True)

    # Add colorbar for topics
    plt.colorbar(scatter, ax=ax, ticks=np.arange(top_n))

    # Save and display the plot
    plt.tight_layout()
    plt.savefig("BERTopic_Example_Cluster_Plot.png")
    plt.show()

def visualize_pylda(lda_model: gensim.models.LdaMulticore, corpus:List[List[Tuple[int, int]]] ,id2word: corpora.Dictionary):
    # Enable the notebook display for pyLDAvis
    pyLDAvis.enable_notebook()

    # Visualize the topics
    vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)

    # Display the visualization
    pyLDAvis.display(vis)


def visualize_confusion_matrix(y_pred, y_true):

    cm = confusion_matrix(y_true, y_pred)
    fig, ax = plt.subplots(figsize=(6,6))

    display = ConfusionMatrixDisplay(confusion_matrix=cm)

    display.plot(cmap='Blues',
                 ax=ax,
                 colorbar=False)

    plt.savefig("confusion_matrix.png")


